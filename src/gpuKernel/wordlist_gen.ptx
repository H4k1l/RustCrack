//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33191640
// Cuda compilation tools, release 12.2, V12.2.140
// Based on NVVM 7.0.1
//

.version 8.2
.target sm_52
.address_size 64

	// .globl	gen_word

.visible .entry gen_word(
	.param .u64 gen_word_param_0,
	.param .u32 gen_word_param_1,
	.param .u64 gen_word_param_2,
	.param .u32 gen_word_param_3,
	.param .u64 gen_word_param_4
)
{
	.reg .pred 	%p<15>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<112>;
	.reg .b64 	%rd<57>;


	ld.param.u64 	%rd12, [gen_word_param_0];
	ld.param.u32 	%r38, [gen_word_param_1];
	ld.param.u64 	%rd13, [gen_word_param_2];
	ld.param.u32 	%r39, [gen_word_param_3];
	ld.param.u64 	%rd14, [gen_word_param_4];
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd2, %rd12;
	cvta.to.global.u64 	%rd3, %rd13;
	mov.u32 	%r40, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r1, %r41, %r40, %r42;
	setp.ge.s32 	%p1, %r1, %r39;
	@%p1 bra 	$L__BB0_18;

	setp.lt.s32 	%p2, %r1, 1;
	mov.u32 	%r104, 0;
	@%p2 bra 	$L__BB0_7;

	add.s32 	%r47, %r1, -1;
	and.b32  	%r103, %r1, 3;
	setp.lt.u32 	%p3, %r47, 3;
	mov.u32 	%r99, 0;
	mov.u32 	%r104, %r99;
	@%p3 bra 	$L__BB0_5;

	sub.s32 	%r97, %r1, %r103;

$L__BB0_4:
	mul.lo.s32 	%r50, %r99, 3;
	mul.wide.s32 	%rd15, %r50, 8;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.u64 	%rd17, [%rd16+8];
	ld.global.u64 	%rd18, [%rd16+16];
	sub.s64 	%rd19, %rd18, %rd17;
	cvt.u32.u64 	%r51, %rd19;
	add.s32 	%r52, %r51, 1;
	ld.global.u32 	%r53, [%rd16];
	add.s32 	%r54, %r53, 1;
	mad.lo.s32 	%r55, %r52, %r54, %r104;
	ld.global.u64 	%rd20, [%rd16+32];
	ld.global.u64 	%rd21, [%rd16+40];
	sub.s64 	%rd22, %rd21, %rd20;
	cvt.u32.u64 	%r56, %rd22;
	add.s32 	%r57, %r56, 1;
	ld.global.u32 	%r58, [%rd16+24];
	add.s32 	%r59, %r58, 1;
	mad.lo.s32 	%r60, %r57, %r59, %r55;
	ld.global.u64 	%rd23, [%rd16+56];
	ld.global.u64 	%rd24, [%rd16+64];
	sub.s64 	%rd25, %rd24, %rd23;
	cvt.u32.u64 	%r61, %rd25;
	add.s32 	%r62, %r61, 1;
	ld.global.u32 	%r63, [%rd16+48];
	add.s32 	%r64, %r63, 1;
	mad.lo.s32 	%r65, %r62, %r64, %r60;
	ld.global.u64 	%rd26, [%rd16+80];
	ld.global.u64 	%rd27, [%rd16+88];
	sub.s64 	%rd28, %rd27, %rd26;
	cvt.u32.u64 	%r66, %rd28;
	add.s32 	%r67, %r66, 1;
	ld.global.u32 	%r68, [%rd16+72];
	add.s32 	%r69, %r68, 1;
	mad.lo.s32 	%r104, %r67, %r69, %r65;
	add.s32 	%r99, %r99, 4;
	add.s32 	%r97, %r97, -4;
	setp.ne.s32 	%p4, %r97, 0;
	@%p4 bra 	$L__BB0_4;

$L__BB0_5:
	setp.eq.s32 	%p5, %r103, 0;
	@%p5 bra 	$L__BB0_7;

$L__BB0_6:
	.pragma "nounroll";
	mul.lo.s32 	%r70, %r99, 3;
	mul.wide.s32 	%rd29, %r70, 8;
	add.s64 	%rd30, %rd3, %rd29;
	ld.global.u64 	%rd31, [%rd30+8];
	ld.global.u64 	%rd32, [%rd30+16];
	sub.s64 	%rd33, %rd32, %rd31;
	cvt.u32.u64 	%r71, %rd33;
	add.s32 	%r72, %r71, 1;
	ld.global.u32 	%r73, [%rd30];
	add.s32 	%r74, %r73, 1;
	mad.lo.s32 	%r104, %r72, %r74, %r104;
	add.s32 	%r99, %r99, 1;
	add.s32 	%r103, %r103, -1;
	setp.ne.s32 	%p6, %r103, 0;
	@%p6 bra 	$L__BB0_6;

$L__BB0_7:
	mul.lo.s32 	%r20, %r1, 3;
	mul.wide.s32 	%rd34, %r20, 8;
	add.s64 	%rd4, %rd3, %rd34;
	ld.global.u64 	%rd5, [%rd4+8];
	cvt.s64.s32 	%rd35, %rd5;
	ld.global.u64 	%rd36, [%rd4+16];
	setp.lt.u64 	%p7, %rd36, %rd35;
	@%p7 bra 	$L__BB0_18;

	cvt.u32.u64 	%r105, %rd5;
	add.s64 	%rd7, %rd1, 3;

$L__BB0_9:
	ld.global.u32 	%r24, [%rd4];
	setp.lt.s32 	%p8, %r24, 1;
	@%p8 bra 	$L__BB0_17;

	add.s32 	%r76, %r24, -1;
	and.b32  	%r25, %r24, 3;
	setp.lt.u32 	%p9, %r76, 3;
	mov.u32 	%r110, 0;
	mov.u32 	%r111, %r105;
	@%p9 bra 	$L__BB0_13;

	sub.s32 	%r109, %r24, %r25;
	cvt.s64.s32 	%rd38, %r104;
	add.s64 	%rd56, %rd7, %rd38;
	mov.u32 	%r111, %r105;

$L__BB0_12:
	div.s32 	%r78, %r111, %r38;
	mul.lo.s32 	%r79, %r78, %r38;
	sub.s32 	%r80, %r111, %r79;
	cvt.s64.s32 	%rd39, %r80;
	add.s64 	%rd40, %rd2, %rd39;
	ld.global.u8 	%rs1, [%rd40];
	st.global.u8 	[%rd56+-3], %rs1;
	div.s32 	%r81, %r78, %r38;
	mul.lo.s32 	%r82, %r81, %r38;
	sub.s32 	%r83, %r78, %r82;
	cvt.s64.s32 	%rd41, %r83;
	add.s64 	%rd42, %rd2, %rd41;
	ld.global.u8 	%rs2, [%rd42];
	st.global.u8 	[%rd56+-2], %rs2;
	div.s32 	%r84, %r81, %r38;
	mul.lo.s32 	%r85, %r84, %r38;
	sub.s32 	%r86, %r81, %r85;
	cvt.s64.s32 	%rd43, %r86;
	add.s64 	%rd44, %rd2, %rd43;
	ld.global.u8 	%rs3, [%rd44];
	st.global.u8 	[%rd56+-1], %rs3;
	div.s32 	%r111, %r84, %r38;
	mul.lo.s32 	%r87, %r111, %r38;
	sub.s32 	%r88, %r84, %r87;
	cvt.s64.s32 	%rd45, %r88;
	add.s64 	%rd46, %rd2, %rd45;
	ld.global.u8 	%rs4, [%rd46];
	st.global.u8 	[%rd56], %rs4;
	add.s32 	%r110, %r110, 4;
	add.s64 	%rd56, %rd56, 4;
	add.s32 	%r109, %r109, -4;
	setp.ne.s32 	%p10, %r109, 0;
	@%p10 bra 	$L__BB0_12;

$L__BB0_13:
	setp.eq.s32 	%p11, %r25, 0;
	@%p11 bra 	$L__BB0_17;

	rem.s32 	%r89, %r111, %r38;
	cvt.s64.s32 	%rd47, %r89;
	add.s64 	%rd48, %rd2, %rd47;
	ld.global.u8 	%rs5, [%rd48];
	add.s32 	%r90, %r110, %r104;
	cvt.s64.s32 	%rd49, %r90;
	add.s64 	%rd11, %rd1, %rd49;
	st.global.u8 	[%rd11], %rs5;
	setp.eq.s32 	%p12, %r25, 1;
	@%p12 bra 	$L__BB0_17;

	div.s32 	%r35, %r111, %r38;
	rem.s32 	%r91, %r35, %r38;
	cvt.s64.s32 	%rd50, %r91;
	add.s64 	%rd51, %rd2, %rd50;
	ld.global.u8 	%rs6, [%rd51];
	st.global.u8 	[%rd11+1], %rs6;
	setp.eq.s32 	%p13, %r25, 2;
	@%p13 bra 	$L__BB0_17;

	div.s32 	%r92, %r35, %r38;
	rem.s32 	%r93, %r92, %r38;
	cvt.s64.s32 	%rd52, %r93;
	add.s64 	%rd53, %rd2, %rd52;
	ld.global.u8 	%rs7, [%rd53];
	st.global.u8 	[%rd11+2], %rs7;

$L__BB0_17:
	add.s32 	%r94, %r104, %r24;
	add.s32 	%r104, %r94, 1;
	add.s32 	%r105, %r105, 1;
	cvt.s64.s32 	%rd54, %r105;
	ld.global.u64 	%rd55, [%rd4+16];
	setp.ge.u64 	%p14, %rd55, %rd54;
	@%p14 bra 	$L__BB0_9;

$L__BB0_18:
	ret;

}

